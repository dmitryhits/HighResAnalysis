{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src.currents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currents Reader\n",
    "> Module to read currents from the log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/10\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from os.path import getsize\n",
    "\n",
    "from numpy import genfromtxt, datetime64, invert, char, uint32\n",
    "from pytz import timezone\n",
    "\n",
    "from HighResAnalysis.src.analysis import *\n",
    "from HighResAnalysis.utility.utils import *\n",
    "from glob import glob\n",
    "from fastcore.script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Currents(Analysis):\n",
    "    \"\"\"reads in information from the keithley log file\"\"\"\n",
    "\n",
    "    def __init__(self, analysis=None, test_campaign=None, dut=None, begin=None, end=None, averaging=None, verbose=False):\n",
    "        Analysis.__init__(self, test_campaign if analysis is None else analysis.BeamTest.Tag, verbose=verbose)\n",
    "\n",
    "        # Settings\n",
    "        self.Averaging = averaging\n",
    "        self.TimeZone = timezone('Europe/Zurich')\n",
    "        self.DataDir = self.BeamTest.Path.joinpath('hv')\n",
    "\n",
    "        # Info\n",
    "        self.Ana = analysis\n",
    "        self.IsCollection = hasattr(analysis, 'Runs')\n",
    "        self.Collection = None\n",
    "        self.RunPlan = self.load_run_plan()  # required for plotting\n",
    "        self.RunLogs = self.Ana.Run.Info\n",
    "        self.Run = self.load_run()\n",
    "\n",
    "        # Config\n",
    "        self.FileName = self.DataDir.joinpath('data.hdf5')\n",
    "        self.Config = self.init_config()\n",
    "        self.Bias = self.load_bias()\n",
    "\n",
    "        # Times\n",
    "        self.Begin, self.End = self.load_times(begin, end)\n",
    "\n",
    "        # DUT\n",
    "        self.DUTNumber = choose(self.Run.DUT.Number, dut, self.Ana)\n",
    "        self.DUTName = self.get_dut_name()\n",
    "\n",
    "        # HV Device Info\n",
    "        self.Number = self.get_device_number()\n",
    "        self.Channel = self.get_device_channel()\n",
    "        self.Name = self.Config.get(f'HV{self.Number}', 'name')\n",
    "        self.Tag = f'{self.Name}_CH{self.Channel}'\n",
    "        self.Brand = remove_digits(self.Name.split('-')[0])\n",
    "        self.Model = self.Config.get('HV{}'.format(self.Number), 'model')\n",
    "        self.Precision = .005 if '237' in self.Name else .05\n",
    "\n",
    "        # data\n",
    "        self.IgnoreJumps = True\n",
    "        self.Data = self.load_data()\n",
    "\n",
    "        # plotting\n",
    "        self.Graphs = []\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.get()\n",
    "\n",
    "    @property\n",
    "    def server_save_dir(self):\n",
    "        return Path('duts', str(self.Ana.DUT), self.BeamTest.Tag, str(self.Run)) if self.Ana is not None else None\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region INIT\n",
    "    def init_config(self):\n",
    "        fname = self.DataDir.joinpath('config.ini')\n",
    "        if not fname.exists():\n",
    "            server, loc = [Analysis.Config.get('data', n) for n in ['server', 'server dir']]\n",
    "            fname.parent.mkdir(exist_ok=True)\n",
    "            download_file(server, Path(loc).joinpath(*fname.parts[-4:]), fname, out=True)\n",
    "        return Config(self.DataDir.joinpath('config.ini'))\n",
    "\n",
    "    def find_data(self):\n",
    "        if self.FileName.exists():\n",
    "            return True\n",
    "        if self.DataDir.joinpath(self.Tag).is_dir():  # convert raw current data if it exists\n",
    "            self.convert_data()\n",
    "            return True\n",
    "        server, loc = [Analysis.Config.get('data', n) for n in ['server', 'server dir']]\n",
    "        return download_file(server, Path(loc).joinpath(*self.FileName.parts[-4:]), self.FileName.parent, out=True) == 0\n",
    "\n",
    "    def load_data(self):\n",
    "        if not self.find_data():\n",
    "            critical('could not find current data ...')\n",
    "        data = h5py.File(self.FileName, 'r')[self.Tag]\n",
    "        data = data[where((data['timestamps'] >= time_stamp(self.Begin, off=True)) & (data['timestamps'] <= time_stamp(self.End, off=True)))]\n",
    "        if self.IgnoreJumps:  # filter out jumps\n",
    "            c = abs(data['currents'])\n",
    "            data = data[append(False, c[:-1] * 100 > c[1:]) | ~c.astype('?')]  # take out the events that are 100 larger than the previous\n",
    "        data['currents'] *= 1e9 * sign(mean(data['currents']))  # convert to nA and flip sign if current is negative\n",
    "        if self.Ana is not None and data.size:\n",
    "            data['timestamps'] -= uint32(data['timestamps'][0] - self.Run.LogStart)  # synchronise time vectors\n",
    "        return data\n",
    "\n",
    "    def reload_data(self, ignore_jumps):\n",
    "        if ignore_jumps != self.IgnoreJumps:\n",
    "            self.IgnoreJumps = ignore_jumps\n",
    "            self.Data = self.load_data()\n",
    "\n",
    "    def load_bias(self):\n",
    "        return self.Run.DUT.Bias if hasattr(self.Run, 'Bias') else None\n",
    "\n",
    "    def load_run(self):\n",
    "        return None if self.Ana is None else self.Ana.Run if not self.IsCollection else self.Ana.RunPlan\n",
    "\n",
    "    def load_run_plan(self):\n",
    "        return self.Collection.SelectedRunplan if self.Ana is None else self.Ana.RunPlan if self.IsCollection else None\n",
    "\n",
    "    def load_parser(self):\n",
    "        parser = ConfigParser()\n",
    "        file_path = join(self.DataDir, 'config.ini')\n",
    "        if not file_exists(file_path):\n",
    "            critical('HV info file \"{f}\" does not exist'.format(f=file_path))\n",
    "        parser.read(file_path)\n",
    "        self.info('HV Devices: {}'.format(', '.join(name for name in parser.sections() if name.startswith('HV'))))\n",
    "        return parser\n",
    "\n",
    "    def load_times(self, begin, end):\n",
    "        if self.Ana is None:\n",
    "            if str(begin).isdigit():  # run number or run plan is provided\n",
    "                self.Collection.select_runs_in_range(begin, end if end is not None else begin) if end or end is None else self.Collection.select_runs_from_runplan(begin)\n",
    "                return self.Collection.get_start_time(), self.Collection.get_end_time()\n",
    "            else:  # actual time strings are provided\n",
    "                return (self.TimeZone.localize(datetime.strptime(f'{self.BeamTest.year}-{t}', '%Y-%m/%d-%H:%M:%S')) for t in [begin, end])\n",
    "        return [self.TimeZone.localize(t) for t in [self.Ana.StartTime, self.Ana.EndTime]]\n",
    "\n",
    "    def get_dut_name(self):\n",
    "        if self.Ana is not None:\n",
    "            return self.Ana.DUT.Name\n",
    "        elif self.Collection.has_selected_runs():\n",
    "            return self.Collection.get_diamond_names(sel=True)[0]\n",
    "        return next(log['duts'][self.DUTNumber] for log in self.RunLogs.itervalues() if (log['start']) > self.Begin)\n",
    "\n",
    "    def get_device_str(self):\n",
    "        if self.Ana is not None:\n",
    "            run_info = self.RunLogs\n",
    "        elif self.Collection.has_selected_runs():\n",
    "            run_info = self.RunLogs[str(self.Collection.get_selected_runs()[0])]\n",
    "        else:\n",
    "            run_info = next(log for log in self.RunLogs.itervalues() if datetime.timestamp(log['start']) > self.Begin)\n",
    "        return str(run_info['hv supplies'][self.DUTNumber])\n",
    "\n",
    "    def get_device_number(self):\n",
    "        return self.get_device_str().split('-')[0]\n",
    "\n",
    "    def get_device_channel(self):\n",
    "        words = self.get_device_str().split('-')\n",
    "        return words[1] if len(words) > 1 else '0'\n",
    "\n",
    "    def find_data_path(self):\n",
    "        data_dir = join(self.Run.TCDir, 'hv', f'{self.Name}_CH{self.Channel}')\n",
    "        if not dir_exists(data_dir):\n",
    "            critical(f'HV data path \"{data_dir}\" does not exist!')\n",
    "        return data_dir\n",
    "\n",
    "    def load_time(self, t, t_log):\n",
    "        t = self.TimeZone.localize(choose(t, t_log))\n",
    "        return t_log if t.year < 2000 or t.day != t_log.day else t\n",
    "\n",
    "    def load_ana_start_time(self):\n",
    "        ana = self.Ana if not self.IsCollection else self.Ana.FirstAnalysis\n",
    "        return self.load_time(ana.StartTime if hasattr(ana.Run, 'StartTime') else None, datetime.fromtimestamp(ana.Run.LogStart))\n",
    "\n",
    "    def load_ana_end_time(self):\n",
    "        ana = self.Ana if not self.IsCollection else self.Ana.LastAnalysis\n",
    "        return self.load_time(ana.EndTime if hasattr(ana.Run, 'EndTime') else None, datetime.fromtimestamp(ana.Run.LogEnd))\n",
    "\n",
    "    def get_title(self):\n",
    "        bias_str = 'at {b} V'.format(b=self.Bias) if self.Bias else ''\n",
    "        run_str = '{n}'.format(n=self.Run.Number) if not self.IsCollection else 'Plan {rp}'.format(rp=self.Ana.RunPlan)\n",
    "        return 'Currents of {dia} {b} - Run {r} - {n}'.format(dia=self.DUTName, b=bias_str, r=run_str, n=self.Name)\n",
    "    # endregion INIT\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region GET\n",
    "    @property\n",
    "    def currents(self):\n",
    "        return self.Data['currents']\n",
    "    # endregion GET\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region DATA ACQUISITION\n",
    "    def get_log_date(self, name):\n",
    "        log_date = ''.join(basename(name).split('_')[-6:])\n",
    "        return self.TimeZone.localize(datetime.strptime(log_date, '%Y%m%d%H%M%S.log'))\n",
    "\n",
    "    def convert_data(self):\n",
    "        info('converting hv text files to hdf5 ...')\n",
    "        PBAR.start(len(glob(join(self.DataDir, '*', '*.log'))))\n",
    "        f = h5py.File(join(self.DataDir, 'data.hdf5'), 'w')\n",
    "        for d in glob(join(self.DataDir, '*_*')):\n",
    "            arrays = []\n",
    "            for file_name in glob(join(d, '*.log')):\n",
    "                if getsize(file_name) == 0:\n",
    "                    remove_file(file_name)\n",
    "                    continue\n",
    "                log_date = self.get_log_date(file_name)\n",
    "                data = genfromtxt(file_name, usecols=arange(3), dtype=[('timestamps', object), ('voltages', 'f2'), ('currents', 'f4')])\n",
    "                if not data.shape:\n",
    "                    remove_file(file_name)\n",
    "                    continue\n",
    "                data = data[where(invert(isnan(data['voltages'])))[0]]  # remove text entries\n",
    "                date_times = array(log_date.strftime('%Y-%m-%d ') + char.array(data['timestamps'].astype('U'))).astype(datetime64).astype(datetime)\n",
    "                data['timestamps'] = (array([time_stamp(dt, log_date.utcoffset().seconds) for dt in date_times]).astype('u4'))\n",
    "                data = data.astype([('timestamps', 'u4'), ('voltages', 'f2'), ('currents', 'f4')])\n",
    "                arrays.append(data)\n",
    "                PBAR.update()\n",
    "            if len(arrays):\n",
    "                f.create_dataset(basename(d), data=concatenate(arrays))\n",
    "    # endregion DATA ACQUISITION\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region PLOTTING\n",
    "    def draw_profile(self, bw=None, **dkw):\n",
    "        x, y = self.Data['timestamps'], self.Data['currents']\n",
    "        return self.Draw.profile(x, y, bins.find(x, w=bw), title='Leakage Current', **prep_kw(dkw, x_tit='Time [hh:mm]', y_tit='Current [nA]', t_ax_off=0, markersize=.7, **Draw.mode(2)))\n",
    "\n",
    "    def draw_distribution(self, **dkw):\n",
    "        return self.Draw.distribution(self.Data['currents'], title='Current Dist', **prep_kw(dkw, x_tit='Current [nA]', file_name='CurrDist'))\n",
    "\n",
    "    def get(self):\n",
    "        if self.Ana is not None and not self.Ana.DUT.Bias:\n",
    "            warning(f'Bias of run {self.Ana.Run} is 0!')\n",
    "            return ufloat(0, 0)\n",
    "        else:\n",
    "            x = self.currents\n",
    "            if all(x == x[0]):\n",
    "                return ufloat(x[0], self.Precision)\n",
    "            h = self.draw_distribution(show=False, save=False)\n",
    "            if h.GetEntries() < 3:\n",
    "                return None\n",
    "            m, s = mean_sigma(*hist_xy(h, err=False), err=False)\n",
    "            fit = h.Fit('gaus', 'sq0', '', m - 2 * s, m + 2 * s)\n",
    "            fm, fs = fit.Parameter(1), fit.Parameter(2)\n",
    "            if .8 * m < fm < 1.2 * m and s > 0 and fs < fm and fit.ParError(1) < m:  # only use gauss fit if it's not deviating too much from the mean\n",
    "                current = ufloat(fm, fs + self.Precision + .03 * fm)  # add .05 as uncertainty of the device and 5% systematic error\n",
    "            else:\n",
    "                current = ufloat(h.GetMean(), h.GetMeanError() + .05 + .05 * h.GetMean())\n",
    "        return current\n",
    "\n",
    "    def draw_iv(self, **dkw):\n",
    "        return self.Draw.graph(self.Data['voltages'], self.Data['currents'], f'I-V Curve for {self.DUTName}', **prep_kw(dkw, x_tit='Voltage [V]', y_tit='Current [nA]'))\n",
    "\n",
    "    def draw(self, rel_time=False, ignore_jumps=True, v_range=None, c_range=None, averaging=1, **dkw):\n",
    "        self.reload_data(ignore_jumps)\n",
    "        t, c, v = (average_list(self.Data[n], averaging) for n in ['timestamps', 'currents', 'voltages'])\n",
    "        gv = self.Draw.graph(t, v, self.get_title(), y_tit='Voltage [nA]', yax_col=602, color=602, y_range=choose(v_range, [-100, 0]), l_off_x=10, x_ticks=0, show=False)\n",
    "        gc = self.Draw.graph(t, c, x_tit='Time [hh:mm]', y_tit='Current [nA]', yax_col=899, color=899, y_range=choose(c_range, [round_down_to(min(c)), round_up_to(max(c))]), show=False)\n",
    "        for g in [gc, gv]:\n",
    "            format_histo(g, lab_size=.05, x_off=1.05, tit_size=.06, t_ax_off=t[0] if rel_time else 0, y_off=.8, center_y=True, x_range=[t[0], t[-1]], markersize=.3)\n",
    "        self.Draw(gv, **prep_kw(dkw, save=False, **Draw.mode(2, lm=.1, rm=.1), draw_opt='aly+'))\n",
    "        self.Draw.tpad('pc', transparent=True, c=get_last_canvas())\n",
    "        gc.Draw(dkw['draw_opt'] if 'draw_opt' in dkw else 'al')\n",
    "        self.Draw.save_plots('Currents')\n",
    "    # endregion PLOTTING\n",
    "    # ----------------------------------------\n",
    "\n",
    "    def run_exists(self, run):\n",
    "        if run in self.RunLogs:\n",
    "            return True\n",
    "        else:\n",
    "            warning(f'Run {run} does not exist in {self.BeamTest}!')\n",
    "            return False\n",
    "\n",
    "    def print_run_times(self, run):\n",
    "        run = str(run)\n",
    "        if not self.run_exists(run):\n",
    "            return\n",
    "        log = self.RunLogs[run]\n",
    "        out = '{date}: {start}-{stop}'.format(date=log['begin date'], start=log['begin time'], stop=log['stop time'])\n",
    "        print(out)\n",
    "\n",
    "    def get_time_from_log(self, t_str, year_str):\n",
    "        return self.TimeZone.localize(datetime.strptime(year_str.strftime('%Y%m%d') + t_str, '%Y%m%d%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@call_parse\n",
    "def main(v:Param(action='store_false'),\n",
    "         collection:Param(action='store_true', help='begin analysis collection'),\n",
    "         dut:int=1, # dut number [default: 1] (choose from 1,2,...)\n",
    "         begin:int=12,\n",
    "         end:int=None,\n",
    "         test_campaign:str=None, # YYYYMM beam test [default in main.ini]\n",
    "        ):\n",
    "\n",
    "#     from argparse import ArgumentParser\n",
    "\n",
    "#     aparser = ArgumentParser()\n",
    "#     aparser.add_argument('dut', nargs='?', default=1, type=int, help='dut number [default: 1] (choose from 1,2,...)')\n",
    "#     aparser.add_argument('begin', nargs='?', default=12)\n",
    "#     aparser.add_argument('end', nargs='?', default=None)\n",
    "#     aparser.add_argument('-tc', '--testcampaign', nargs='?', default=None, help='YYYYMM beam test [default in main.ini]')\n",
    "#     aparser.add_argument('-v', '--verbose', action='store_false')\n",
    "#     aparser.add_argument('-c', '--collection', action='store_true', help='begin analysis collection')\n",
    "#     pargs = aparser.parse_args()\n",
    "\n",
    "    z = Currents(test_campaign=testcampaign, dut=dut, begin=begin, end=end if not collection else False, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
