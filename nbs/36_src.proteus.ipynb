{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src.proteus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteus\n",
    "> alignment and tracking of telescope data with proteus (created on April 14th 2022 by M. Reichmann (remichae@phys.ethz.ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/10\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from os import chdir\n",
    "import toml\n",
    "from numpy import array, arange\n",
    "from HighResAnalysis.plotting.utils import info, warning, choose, remove_file, critical\n",
    "from HighResAnalysis.utility.utils import print_banner, GREEN, print_elapsed_time, wraps, remove_letters, byte2str\n",
    "from HighResAnalysis.src.analysis import Analysis, Dir\n",
    "from subprocess import check_call, CalledProcessError\n",
    "from shutil import copytree\n",
    "from copy import deepcopy\n",
    "from fastcore.script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_toml(name):\n",
    "    def inner(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, arg=None):\n",
    "            default = self.ConfigDir.joinpath(f'{name}.toml')\n",
    "            if arg is None:\n",
    "                return default\n",
    "            d = toml.load(default)\n",
    "            func(self, arg, d)\n",
    "            tmp = self.ConfigDir.joinpath(f'tmp-{name[:3]}-{self.RunNumber}.toml')\n",
    "            with open(tmp, 'w') as f:\n",
    "                toml.dump(d, f)\n",
    "            return tmp\n",
    "        return wrapper\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Proteus:\n",
    "    \"\"\" Alignment and tracking of telescope data.\n",
    "        STEP 1: noisescan\n",
    "        STEP 2: alignment\n",
    "        STEP 3: tracking\n",
    "        STEP 4: track-matching  \"\"\"\n",
    "\n",
    "    Si_Detectors = ['D8', 'Si-D8']\n",
    "\n",
    "    def __init__(self, soft_dir, data_dir, cfg_dir, raw_file, max_events=None, skip_events=None, dut_pos=None, duts=None, align_run=None):\n",
    "\n",
    "        # DIRECTORIES\n",
    "        self.SoftDir = Path(soft_dir)\n",
    "        self.DataDir = Path(data_dir)\n",
    "        self.ConfigDir = Path(cfg_dir)\n",
    "        self.MaskDir = Path('mask')\n",
    "\n",
    "        # CONFIG\n",
    "        self.NTelPlanes = sum([d['name'].startswith('M') for d in toml.load(str(self.ConfigDir.joinpath('device.toml')))['sensors']])\n",
    "        self.NRefPlanes = sum(['REF' in d['type'] for d in toml.load(str(self.ConfigDir.joinpath('device.toml')))['sensors']])\n",
    "        self.MaxDUTs = len(toml.load(str(self.ConfigDir.joinpath('geometry.toml')))['sensors']) - self.NTelPlanes - 1  # default geo has all sensors (tel, ref and dut)\n",
    "        self.DUTs = duts\n",
    "        self.DUTPos = dut_pos\n",
    "\n",
    "        self.RawFilePath = Path(raw_file)\n",
    "        self.RunNumber = int(''.join(filter(lambda x: x.isdigit(), self.RawFilePath.stem)))\n",
    "        self.AlignRun = choose(align_run, self.RunNumber)\n",
    "        self.RawGeo = self.init_raw_geo(dut_pos)  # geometry before any alignment\n",
    "        self.Device = self.init_device(duts)\n",
    "        self.Ana = self.init_ana(duts)\n",
    "\n",
    "        self.Out = self.DataDir.joinpath(f'tracked-{self.RunNumber:04d}')           # name for proteus\n",
    "        self.OutFilePath = self.Out.with_name(f'{self.Out.name}-trees.root')        # final file\n",
    "        self.HistFilePath = self.Out.with_name(f'{self.Out.name}-hists.root')       # file with histograms\n",
    "        self.TrackName = self.DataDir.joinpath(f'clustered-{self.RunNumber:04d}')   # tracking file for alignment\n",
    "\n",
    "        # ALIGNMENT\n",
    "        self.N = max_events\n",
    "        self.S = skip_events\n",
    "        self.AlignDir = Path('alignment')\n",
    "        self.Align = self.init_align(self.DUTs)  # configuration\n",
    "        self.AlignSteps = list(toml.load(str(self.Align))['align'])\n",
    "\n",
    "        self.Steps = [(self.noise_scan, self.toml_name(self.dut_names[-1], 'mask', 'mask')), (self.align, self.align_file), (self.recon, self.OutFilePath)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Proteus interface for run {self.RunNumber} ({self.RawFilePath.name})'\n",
    "\n",
    "    def __del__(self):\n",
    "        remove_file(*self.ConfigDir.glob(f'tmp-*-{self.RunNumber}.toml'), warn=False)  # remove tmp files\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region INIT\n",
    "    def __create_default_cfg(self):\n",
    "        copytree(self.ConfigDir.with_name('default'), self.ConfigDir)\n",
    "\n",
    "    @init_toml('geometry')\n",
    "    def init_raw_geo(self, dut_pos, data=None):\n",
    "        for i in range(self.MaxDUTs):  # remove non-existing DUTs\n",
    "            if i not in dut_pos:\n",
    "                data['sensors'].pop(i - self.MaxDUTs)\n",
    "        for i, dic in enumerate(data['sensors']):  # fix ids\n",
    "            dic['id'] = i\n",
    "\n",
    "    def init_geo(self):\n",
    "        \"\"\"parse the aligned geometry file in case not all DUTs were selected. Should only be used after alignment was done.\"\"\"\n",
    "        f = self.align_file\n",
    "        data = toml.load(str(f))\n",
    "        ndut = len(data['sensors']) - self.NTelPlanes - self.NRefPlanes\n",
    "        dut_nrs = [min(i, ndut - 1) for i in self.DUTPos]  # nr of DUT required not the position\n",
    "        for i in range(ndut):  # remove non-existing DUTs\n",
    "            if i not in dut_nrs:\n",
    "                data['sensors'].pop(i - ndut)\n",
    "        for i, dic in enumerate(data['sensors']):  # fix ids\n",
    "            dic['id'] = i\n",
    "        tmp = self.ConfigDir.joinpath(f'tmp-{f.name}')\n",
    "        with open(tmp, 'w') as ftmp:\n",
    "            toml.dump(data, ftmp)\n",
    "        return tmp\n",
    "\n",
    "    @init_toml('device')\n",
    "    def init_device(self, duts, data=None):\n",
    "        s = [dic for dic in data['sensors'] if dic['name'].startswith('M') or 'REF' in dic['type']]  # only select TEL & REF planes\n",
    "        s += [{'type': 'CMSPixel-Si' if dut in Proteus.Si_Detectors else 'CMSPixel-Dia', 'name': f'C{i}'} for i, dut in enumerate(duts)]  # add all given DUTs\n",
    "        data['sensors'] = s\n",
    "        data['pixel_masks'] = [str(self.MaskDir.joinpath(f'{n}-mask.toml')) for n in ['tel'] + self.dut_names + (['ref'] if self.NRefPlanes else [])]\n",
    "\n",
    "    @init_toml('analysis')\n",
    "    def init_ana(self, duts, data=None):\n",
    "        data['recon']['extrapolation_ids'] = list(range(self.NTelPlanes + self.NRefPlanes + len(duts)))\n",
    "\n",
    "    @init_toml('noisescan')\n",
    "    def init_noise(self, duts, data=None):  # noqa\n",
    "        new = {'tel': data['noisescan']['tel'], 'ref': data['noisescan']['ref']}  # only select the telescope & ref settings\n",
    "        for i, key in enumerate(self.dut_names):  # add only existing DUTs\n",
    "            if key not in data['noisescan']:\n",
    "                critical(f'There is not entry for the DUT \"{key}\" in {self.ConfigDir.joinpath(\"noisescan.toml\")}')\n",
    "            data['noisescan'][key]['sensors'][0]['id'] = self.NTelPlanes + self.NRefPlanes + i\n",
    "            new[key] = data['noisescan'][key]\n",
    "        data['noisescan'] = new\n",
    "\n",
    "    @init_toml('align')\n",
    "    def init_align(self, duts=None, data=None):\n",
    "        default_steps = deepcopy(data['align'])\n",
    "        dut_fine = next(dic for step, dic in default_steps.items() if 'dut_fine' in step)\n",
    "        for step in default_steps:\n",
    "            t, r, d = self.NTelPlanes, self.NRefPlanes, len(duts)\n",
    "            if 'dut_coarse' in step:\n",
    "                data['align'][step]['sensor_ids'] = list(range(t + r + d))\n",
    "                data['align'][step]['align_ids'] = (arange(d + r) + t).tolist()\n",
    "            elif 'dut_fine' in step:\n",
    "                for i in range(len(duts)):  # align each DUT individually\n",
    "                    step = f'{int(remove_letters(step)) + i}-dut_fine'\n",
    "                    data['align'].update({step: deepcopy(dut_fine)})\n",
    "                    data['align'][step]['sensor_ids'] = list(range(t)) + [t + r + i]\n",
    "                    data['align'][step]['align_ids'] = [t + r + i]\n",
    "    # endregion INIT\n",
    "    # ----------------------------------------\n",
    "\n",
    "    @property\n",
    "    def align_file(self):\n",
    "        files = sorted([f for f in self.ConfigDir.joinpath(self.AlignDir).glob('*.toml') if self.AlignRun >= int(remove_letters(f.stem))], reverse=True)\n",
    "        return files[0] if len(files) else Path('None')\n",
    "\n",
    "    @property\n",
    "    def has_alignment(self):\n",
    "        return self.align_file.exists()\n",
    "\n",
    "    def alignment(self):\n",
    "        return toml.load(str(self.align_file))\n",
    "\n",
    "    def z_positions(self, raw=False):\n",
    "        d = toml.load(str(self.RawGeo if raw else self.align_file))\n",
    "        return array([s['offset'][-1] for s in d['sensors']])\n",
    "\n",
    "    @property\n",
    "    def dut_names(self):\n",
    "        return ['ref', 'dut'] if self.DUTs is None else self.DUTs\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region MISC\n",
    "    def toml_name(self, name=None, d='alignment', typ='geo'):\n",
    "        return self.ConfigDir.joinpath(d, f'{self.AlignSteps[-1] if name is None else name}-{typ}.toml')\n",
    "\n",
    "    def make_empty_masks(self, cfg):\n",
    "        for section in cfg:\n",
    "            m = self.toml_name(section, d='mask', typ='mask')\n",
    "            if not m.exists():\n",
    "                m.write_text('[[sensors]]\\nid = 0\\nmasked_pixels = []\\n')\n",
    "\n",
    "    def remove_root_files(self):\n",
    "        for f in self.ConfigDir.rglob('*.root'):\n",
    "            remove_file(f)\n",
    "\n",
    "    def remove_alignment(self):\n",
    "        remove_file(self.align_file)\n",
    "\n",
    "    def remove_mask(self):\n",
    "        for f in self.ConfigDir.joinpath('mask').glob('*.toml'):\n",
    "            remove_file(f)\n",
    "\n",
    "    def clean_tmp(self):\n",
    "        f = list(self.ConfigDir.parent.rglob('tmp-*'))\n",
    "        info(f'removing {len(f)} temporary files ({byte2str(sum([i.stat().st_size for i in f]))})')\n",
    "        remove_file(*f, warn=False)\n",
    "    # endregion MISC\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region RUN\n",
    "    def run(self, prog, out: Path, cfg=None, geo=None, dev=None, section=None, f=None, n=None, s=None, progress=True):\n",
    "        old_dir = Path.cwd()\n",
    "        chdir(self.ConfigDir)  # proteus needs to be in the directory where all the toml files are (for the default args)...\n",
    "        cfg = '' if cfg is None else f'-c {str(cfg).replace(\".toml\", \"\")}.toml'\n",
    "        section = '' if section is None else f'-u {section}'\n",
    "        geo = f'-g {choose(geo, self.RawGeo)}'\n",
    "        dev = f'-d {choose(dev, self.Device)}'\n",
    "        n = f'-n {choose(n, self.N)}' if choose(n, self.N) is not None else ''\n",
    "        s = f'-s {choose(s, self.S)}' if choose(s, self.S) is not None else ''\n",
    "        p = '' if progress else '--no-progress'\n",
    "        in_file = choose(f, self.RawFilePath)\n",
    "        if not Path(in_file).exists():\n",
    "            return warning(f'Could not find {in_file} for proteus to read ... ')\n",
    "        opts = ' '.join([cfg, dev, geo, section, n, s, p])\n",
    "        cmd = f'{self.SoftDir.joinpath(\"bin\", prog)} {in_file} {out} {opts}'\n",
    "        info(cmd)\n",
    "        try:\n",
    "            check_call(cmd, shell=True)\n",
    "        except CalledProcessError:\n",
    "            warning(f'{prog} failed!')\n",
    "        chdir(old_dir)\n",
    "\n",
    "    def noise_scan(self, section=None, rm_root=True):\n",
    "        \"\"\" step 1: find noisy pixels. \"\"\"\n",
    "        f_cfg = self.init_noise(self.DUTs)\n",
    "        cfg = toml.load(str(f_cfg))['noisescan']\n",
    "        self.ConfigDir.joinpath(self.MaskDir).mkdir(exist_ok=True)\n",
    "        self.make_empty_masks(cfg)\n",
    "        for section in cfg if section is None else [section]:\n",
    "            print_banner(f'Starting noise scan for {section}', color=GREEN)\n",
    "            self.run('pt-noisescan', out=self.MaskDir.joinpath(section), cfg=f_cfg.stem, section=section)\n",
    "        if rm_root:\n",
    "            remove_file(*self.ConfigDir.joinpath(self.MaskDir).glob('*.root'), warn=False)\n",
    "\n",
    "    def align(self, step=None, force=False, n=100000):\n",
    "        \"\"\" step 2: align the telescope in several steps. \"\"\"\n",
    "        t = info('Starting alignment ...')\n",
    "        self.ConfigDir.joinpath(self.AlignDir).mkdir(exist_ok=True)\n",
    "        cfg = self.init_align(self.DUTs).stem\n",
    "        for i in range(len(self.AlignSteps)) if step is None else [step]:\n",
    "            s = self.AlignSteps[i]\n",
    "            if not self.toml_name(s).exists() or force:\n",
    "                self.run('pt-align', out=self.AlignDir.joinpath(s), geo=self.toml_name(self.AlignSteps[i - 1]) if i else None, section=s, cfg=cfg, n=n * 3 if 'dut' in s else n)\n",
    "            else:\n",
    "                warning(f'geo file \"{s}\" already exists!')\n",
    "        if step is None:\n",
    "            final_file = self.toml_name()\n",
    "            final_file.rename(final_file.with_name(f'{self.RunNumber:03d}-geo.toml'))  # rename the final alignment file\n",
    "            remove_file(*[self.toml_name(s) for s in self.AlignSteps])  # remove auxiliary geo files\n",
    "            remove_file(*self.ConfigDir.joinpath(self.AlignDir).glob('*.root'))  # remove hist files\n",
    "        print_elapsed_time(t)\n",
    "\n",
    "    def recon(self, cfg=None, progress=True, section=None):\n",
    "        \"\"\" step 3: based on the alignment generate the tracks with proteus. \"\"\"\n",
    "        self.Out.parent.mkdir(exist_ok=True)\n",
    "        self.run('pt-recon', out=self.Out, cfg=choose(cfg, self.Ana), geo=self.init_geo(), progress=progress, section=section)\n",
    "\n",
    "    def track(self):\n",
    "        \"\"\" tracking and clustering (obsolete, now done with \"recon\"). \"\"\"\n",
    "        self.Out.parent.mkdir(exist_ok=True)\n",
    "        self.run('pt-track', out=self.TrackName)\n",
    "    # endregion RUN\n",
    "    # ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def main():\n",
    "    a = Analysis()\n",
    "    sdir = Path(a.Config.get('SOFTWARE', 'dir')).expanduser().joinpath(a.Config.get('SOFTWARE', 'proteus'))\n",
    "    f_ = a.BeamTest.Path.joinpath('data', f'run{11:06d}.root')\n",
    "    z = Proteus(sdir, a.BeamTest.Path.joinpath('proteus'), Dir.joinpath('proteus'), f_, a.Config.getint('align', 'max events'), a.Config.getint('align', 'skip events'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
