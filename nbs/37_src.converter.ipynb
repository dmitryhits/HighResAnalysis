{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src.converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter\n",
    "> adds clustering and charge to trees created with pXar (created on August 30th 2018 by M. Reichmann (remichae@phys.ethz.ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import uproot\n",
    "from numpy import all, ones, count_nonzero, array  # noqa\n",
    "from uproot import ReadOnlyDirectory\n",
    "from uproot.models import TTree\n",
    "from pathlib import Path\n",
    "import awkward as aw  \n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "from inspect import signature\n",
    "from subprocess import check_call\n",
    "import h5py\n",
    "\n",
    "from HighResAnalysis.src.proteus import Proteus\n",
    "from HighResAnalysis.src.run import Run, Analysis, init_batch, DUT, Batch\n",
    "from HighResAnalysis.src.analysis import BeamTest\n",
    "from HighResAnalysis.utility.utils import *\n",
    "from HighResAnalysis.utility.utils import Dir\n",
    "# from HighResAnalysis.src.raw import Raw\n",
    "from HighResAnalysis.src.calibration import Calibration\n",
    "from HighResAnalysis.src.dut import Plane\n",
    "from HighResAnalysis.plotting.draw import Draw\n",
    "from HighResAnalysis.plotting.utils import warning, download_file, remove_file, add_to_info, GREEN, prep_kw, choose, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Converter:\n",
    "    \"\"\"\n",
    "    Converts EUDAQ2 raw files in several steps into hdf5 files.\n",
    "    STEP  0: raw -> root                  (EUDAQ2)\n",
    "    STEP  1: noisescan                    (proteus)\n",
    "    STEP  2: alignment                    (proteus)\n",
    "    STEP  3: track reconstruction         (proteus)\n",
    "    STEP  4: root -> hdf5                 (python)\n",
    "    \"\"\"\n",
    "\n",
    "    DUTName = None\n",
    "\n",
    "    def __init__(self, data_dir: Path, run_number, dut_name=None):\n",
    "        print('************** Initing Converter *****************')\n",
    "\n",
    "        self.T0 = time()\n",
    "        self.T1 = timedelta(seconds=0)\n",
    "        self.Run = Run(run_number, 0, data_dir)\n",
    "        self.DUTName = dut_name  # only used in CERNConverter\n",
    "        self.DUTs = self.init_duts()\n",
    "\n",
    "        # DIRECTORIES\n",
    "        self.DataDir = data_dir\n",
    "        self.SaveDir = data_dir.joinpath('data')\n",
    "        self.SoftDir = Path(Analysis.Config.get('SOFTWARE', 'dir')).expanduser()\n",
    "\n",
    "        self.NTelPlanes = Analysis.Config.getint('TELESCOPE', 'planes')\n",
    "        self.NDUTPlanes = self.Run.NDUTs\n",
    "\n",
    "        # PRE-CONVERTER\n",
    "        self.Raw = self.init_raw()\n",
    "        self.Proteus = self.init_proteus()\n",
    "\n",
    "        # FILES\n",
    "        self.OutFilePath = self.SaveDir.joinpath(f'run{self.Run:04d}.hdf5')\n",
    "        self.RawFile: ReadOnlyDirectory = None  # noqa\n",
    "        self.F = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} of {self.Run!r}'\n",
    "\n",
    "    def run(self, force=False, steps=None, rm=True):\n",
    "        if force or not self.OutFilePath.exists():\n",
    "            self.T0 = info(f'Starting {self!r}\\n')\n",
    "            for i, (s, f) in enumerate(choose(steps, self.steps)):\n",
    "                if not f.exists() or force:\n",
    "                    print(f'-----starting step {i}')\n",
    "                    print_banner(f'Start converter step {i}: {s.__doc__}')\n",
    "                    try:\n",
    "                        s(force=force) if 'force' in signature(s).parameters else s()\n",
    "                    except Exception as err:\n",
    "                        warning(f'converter crashed: {err}')\n",
    "                        remove_file(f)\n",
    "                        return False\n",
    "                else:\n",
    "                    info(f'found outfile of step {i}, continue with next step ({f})')\n",
    "            if rm:\n",
    "                self.remove_aux_files()\n",
    "            add_to_info(self.T0, f'\\nFinished {self!r} in ', color=GREEN)\n",
    "            self.T1 = timedelta(seconds=time() - self.T0)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def finished(self):\n",
    "        return self.T1.total_seconds() > 0\n",
    "\n",
    "    def raw2root(self, force=True):\n",
    "        self.run(force=force, steps=self.first_steps, rm=False)\n",
    "\n",
    "    def realign(self, rm=True):\n",
    "        self.raw2root()\n",
    "        self.Proteus.align(force=True)\n",
    "        if rm:\n",
    "            self.remove_aux_files()\n",
    "\n",
    "    @property\n",
    "    def first_steps(self):\n",
    "        return self.Raw.Steps\n",
    "\n",
    "    @property\n",
    "    def steps(self):\n",
    "        return self.first_steps + self.Proteus.Steps + [(self.root2hdf5, self.OutFilePath)]\n",
    "\n",
    "    @property\n",
    "    def aux_files(self):\n",
    "        return [self.Proteus.RawFilePath, self.Proteus.OutFilePath, self.Proteus.HistFilePath]\n",
    "\n",
    "    @property\n",
    "    def raw_files(self):\n",
    "        return [self.Raw.RawFilePath]\n",
    "\n",
    "    def remove_files(self, all_=False):\n",
    "        for s, f in self.steps:\n",
    "            if f.suffix == '.root' or f.suffix == '.hdf5' or all_:\n",
    "                remove_file(f)\n",
    "\n",
    "    def remove_raw_files(self, warn=True):\n",
    "        remove_file(*self.raw_files, warn=warn)\n",
    "\n",
    "    def remove_aux_files(self):\n",
    "        remove_file(*self.aux_files)\n",
    "\n",
    "    def clean(self):\n",
    "        self.remove_aux_files()\n",
    "\n",
    "    @staticmethod\n",
    "    def download_raw_file(f: Path, out=True, force=False):\n",
    "        if not f.exists() or force:\n",
    "            server, loc = [Analysis.Config.get('data', n) for n in ['server', 'server dir']]\n",
    "            info(f'downloading DUT raw file from {server}:{loc}', prnt=out)\n",
    "            f.parent.mkdir(exist_ok=True)\n",
    "            return download_file(server, Path(loc).expanduser().joinpath(*f.parts[-4:]), f, out)\n",
    "\n",
    "    def copy_raw_files(self, out=True, force=False):\n",
    "        return [self.download_raw_file(f, out, force) for f in self.raw_files]\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region INIT\n",
    "    @classmethod\n",
    "    def from_run(cls, run: Run, dut_name=None):\n",
    "        conv = cls(run.TCDir, run.Number, dut_name)\n",
    "        conv.Run = run\n",
    "        return conv\n",
    "\n",
    "    @classmethod\n",
    "    def from_ana(cls, run_number, dut=0, ana: Analysis = None):\n",
    "        ana = choose(ana, Analysis)\n",
    "        return cls.from_run(Run.from_ana(run_number, dut, ana))\n",
    "\n",
    "    def init_proteus(self):\n",
    "        soft_dir = self.SoftDir.joinpath(Analysis.Config.get('SOFTWARE', 'proteus'))\n",
    "        data_dir = self.DataDir.joinpath('proteus')\n",
    "        conf_dir = Dir.joinpath('proteus', self.DataDir.stem)\n",
    "        me, se = [Analysis.Config.getint('align', opt) for opt in ['max events', 'skip events']]\n",
    "        print('*************** Initing PROTEUS ******************')\n",
    "        return Proteus(soft_dir, data_dir, conf_dir, raw_file=self.proteus_raw_file_path(), max_events=me, skip_events=se, dut_pos=self.dut_pos, duts=self.dut_names, align_run=self.Run.Number)\n",
    "\n",
    "    def init_raw(self):\n",
    "        return Raw(self)\n",
    "\n",
    "    def init_event_alignment(self):\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def calibration(self):\n",
    "        return Calibration\n",
    "\n",
    "    def init_duts(self):\n",
    "        return [DUT(i, self.Run.Info) for i in range(self.Run.NDUTs)]\n",
    "\n",
    "    @property\n",
    "    def dut_names(self):\n",
    "        return [dut.Name for dut in self.DUTs]\n",
    "\n",
    "    @property\n",
    "    def dut_pos(self):\n",
    "        return [dut.Position for dut in self.DUTs]\n",
    "\n",
    "    def load_calibration(self, dut_nr=None):\n",
    "        return self.calibration(self.Run if dut_nr is None else Run(self.Run.Number, dut_nr, self.Run.TCDir))\n",
    "\n",
    "    def proteus_raw_file_path(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def load_file(self, opt='w'):\n",
    "        return h5py.File(self.OutFilePath, opt)\n",
    "    # endregion INIT\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region HDF5\n",
    "    def root2hdf5(self):\n",
    "        \"\"\" convert tracked root file to hdf5 file. \"\"\"\n",
    "        remove_file(self.OutFilePath)  # remove hdf5 file if it exists\n",
    "        start_time = info('starting root -> hdf5 conversion ...')\n",
    "\n",
    "        self.F = self.load_file()\n",
    "        self.RawFile = uproot.open(self.Proteus.OutFilePath)\n",
    "\n",
    "        self.add_tracks()\n",
    "        self.add_planes()\n",
    "\n",
    "        add_to_info(start_time, '\\nFinished hdf5 conversion in')\n",
    "        self.F.close()\n",
    "        self.F = None\n",
    "\n",
    "    def add_tracks(self):\n",
    "        t0 = info('adding track information ...', endl=False)\n",
    "        g = self.F.create_group('Tracks')\n",
    "        b = array([['evt_frame', 'Events', 'u4'], ['evt_ntracks', 'N', 'u1'],\n",
    "                   ['trk_size',  'Size',   'f2'],\n",
    "                   ['trk_chi2',  'Chi2',   'f2'], ['trk_dof', 'Dof', 'u1'],\n",
    "                   ['trk_du',    'SlopeX', 'f2'], ['trk_dv', 'SlopeY', 'f2']]).T\n",
    "        tree = self.RawFile['C0/tracks_clusters_matched']  # same for all planes\n",
    "        self.add_time_stamp()\n",
    "        self.add_data(tree, g, b)\n",
    "        add_to_info(t0, color=GREEN)\n",
    "\n",
    "    @property\n",
    "    def time_stamp_file(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def get_time_stamp(self):\n",
    "        t = array(uproot.open(self.time_stamp_file)['Event']['TimeStamp'])\n",
    "        return ((t - t[0]) / 1e9).astype('f4')  # time stamp is just a number counting up\n",
    "\n",
    "    def add_time_stamp(self):\n",
    "        self.F.create_group('Event').create_dataset('Time', data=self.get_time_stamp())\n",
    "\n",
    "    def add_planes(self):\n",
    "        n = len(self.RawFile.keys(recursive=False))  # noqa (raises stupid warning)\n",
    "        info(f'adding {n} planes ... ')\n",
    "        PBAR.start(n * 2)\n",
    "        for pl in range(n):\n",
    "            try:\n",
    "                self.add_plane(pl)\n",
    "            except Exception as err:\n",
    "                PBAR.finish()\n",
    "                raise ValueError(f'root2hdf crashed adding plane {pl} having {err}')\n",
    "\n",
    "    def add_plane(self, i):\n",
    "        g = self.F.create_group(f'Plane{i}')\n",
    "        key = list(self.RawFile.keys(recursive=False))[i]\n",
    "\n",
    "        # mask\n",
    "        m_tree = self.RawFile[f'{key}/masked_pixels']\n",
    "        g.create_dataset('Mask', data=array(list(m_tree.arrays(library='np').values()), 'u2'))\n",
    "\n",
    "        # cluster & track interpolations\n",
    "        tree = self.RawFile[f'{key}/tracks_clusters_matched']\n",
    "        self.add_plane_tracks(g, tree)\n",
    "        self.add_clusters(g, tree)\n",
    "        if i >= self.NTelPlanes + self.Proteus.NRefPlanes:\n",
    "            self.add_trigger_info(g)\n",
    "\n",
    "    @update_pbar\n",
    "    def add_plane_tracks(self, group, tree: TTree):\n",
    "        g = group.create_group('Tracks')\n",
    "        b = array([['trk_u', 'U', 'f2'], ['trk_v', 'V', 'f2'], ['trk_col', 'X', 'f4'], ['trk_row', 'Y', 'f4'], ['trk_std_u', 'eU', 'f2'], ['trk_std_v', 'eV', 'f2']]).T\n",
    "        self.add_data(tree, g, b)\n",
    "\n",
    "    @update_pbar\n",
    "    def add_clusters(self, group, tree: TTree):\n",
    "        g = group.create_group('Clusters')\n",
    "        cs = self.add_data(tree, g, array([['clu_size', 'Size', 'u2'], ['evt_nclusters', 'N', 'u2']]).T)['clu_size']\n",
    "        b = array([['clu_u', 'U', 'f2'], ['clu_v', 'V', 'f2'], ['clu_col', 'X', 'f2'], ['clu_row', 'Y', 'f2'], ['clu_value', 'Charge', 'i']]).T\n",
    "        self.add_data(tree, g, b, cut=cs > 0)  # filter out the nan events\n",
    "\n",
    "    def trigger_info_file(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def add_trigger_info(self, group):\n",
    "        tree = uproot.open(self.trigger_info_file())[f'{group.name}/Hits']\n",
    "        g = group.create_group('Trigger')\n",
    "        b = array([[key, key.replace('Trigger', ''), 'u1'] for key in tree.keys(filter_name='Trigger*')]).T\n",
    "        self.add_data(tree, g, b)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_data(tree: TTree, g, b, cut=...):\n",
    "        data = tree.arrays(b[0], library='np')\n",
    "        for i, (old_name, new_name, dtype) in enumerate(b.T):\n",
    "            g.create_dataset(new_name, data=data[old_name][cut].astype(dtype))\n",
    "        return data\n",
    "    # endregion HDF5\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region ALIGN\n",
    "    def align_tree(self):\n",
    "        import uproot\n",
    "        hf = h5py.File(self.OutFilePath)\n",
    "        with uproot.recreate('bla.root') as f:\n",
    "            n = [array(hf[f'Plane{pl}']['Clusters']['Size']) > 0 for pl in range(self.NTelPlanes)]\n",
    "            cut = all(n, axis=0) & (array(hf['Tracks']['Size']) == self.NTelPlanes)\n",
    "            for pl in range(self.NTelPlanes):\n",
    "                d = f.mkdir(f'Plane{pl}')\n",
    "                ci = cut[n[pl]]\n",
    "                i = count_nonzero(ci)\n",
    "                d['Clusters'] = {'NClusters': ones(i, 'i'),\n",
    "                                 'Col': array(hf[f'Plane{pl}']['Clusters']['X'])[ci].astype('d').reshape((-1, 1)),\n",
    "                                 'Row': array(hf[f'Plane{pl}']['Clusters']['Y'])[ci].astype('d').reshape((-1, 1)),\n",
    "                                 'VarCol': ones((i, 1)),\n",
    "                                 'VarRow': ones((i, 1)),\n",
    "                                 'Value': ones((i, 1)),\n",
    "                                 'CovColRow': zeros((i, 1)),\n",
    "                                 'Timing': zeros((i, 1)),\n",
    "                                 'Track': ones((i, 1), 'i')}\n",
    "            f['Plane0']['Clusters'].show()\n",
    "    # endregion ALIGN\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region MISC\n",
    "    @staticmethod\n",
    "    def check_root_version():\n",
    "        v = gROOT.GetVersion()\n",
    "        return True if v.startswith('6') else critical(f'ROOT 6 required for the conversion! Current version: {v}')\n",
    "    # endregion MISC\n",
    "    # ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def batch_converter(cls: Converter):\n",
    "    class BatchConverter(cls):\n",
    "\n",
    "        def __init__(self, beam_test: BeamTest, batch_name):\n",
    "\n",
    "            self.Batch = batch_name if isinstance(batch_name, Batch) else init_batch(batch_name, 0, beam_test)\n",
    "            super().__init__(beam_test.Path, self.Batch.Runs[0].Number, self.Batch.DUTName)\n",
    "            self.OutFilePath = self.Batch.FileName\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f'{self.__class__.__name__} of {self.Batch!r}'\n",
    "\n",
    "        def proteus_raw_file_path(self):\n",
    "            return self.Batch.FileName.with_suffix('.root')\n",
    "\n",
    "        @classmethod\n",
    "        def from_batch(cls, b: Batch):\n",
    "            return cls(b.BeamTest, b)\n",
    "\n",
    "        def trigger_info_file(self):\n",
    "            return super().trigger_info_file().with_name(f'dut-{self.Batch.FileName.stem}.root')\n",
    "\n",
    "        @property\n",
    "        def time_stamp_file(self):\n",
    "            return self.trigger_info_file()\n",
    "\n",
    "    return BatchConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Raw:\n",
    "\n",
    "    def __init__(self, c: Converter, load_file=False, step=-1):\n",
    "\n",
    "        self.Parent = c\n",
    "        self.Run = c.Run\n",
    "        self.NT = c.NTelPlanes\n",
    "        self.ND = c.NDUTPlanes\n",
    "        self.P = range(self.NT)\n",
    "        self.Planes = [Plane(i, typ='TELESCOPE' if i < self.NT else 'DUT') for i in range(self.NT + self.ND)]\n",
    "\n",
    "        self.SoftDir = self.load_soft_dir()\n",
    "        self.DataDir = c.DataDir\n",
    "        self.SaveDir = c.SaveDir\n",
    "\n",
    "        self.RawFilePath = self.load_raw_file_path()\n",
    "        self.OutFilePath = self.load_out_file_path()\n",
    "\n",
    "        if load_file:\n",
    "            self.F = c.F if c.F is not None else h5py.File(c.OutFilePath, 'r')\n",
    "\n",
    "        self.Steps = [(self.convert, self.OutFilePath)]\n",
    "        self.AtStep = step\n",
    "        self.Draw = Draw(Analysis.Config.FilePath)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} file analysis run {self.Run} ({self.RawFilePath.name})'\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region CONVERT\n",
    "    def load_raw_file_path(self):\n",
    "        return self.DataDir.joinpath('raw', f'run{self.Run:06d}.raw')\n",
    "\n",
    "    def load_out_file_path(self):\n",
    "        return self.SaveDir.joinpath(f'run{self.Run:06d}.root')\n",
    "\n",
    "    def load_soft_dir(self):\n",
    "        return self.Parent.SoftDir.joinpath(Analysis.Config.get('SOFTWARE', 'eudaq2'))\n",
    "\n",
    "    def generate_fit_files(self):\n",
    "        c = None\n",
    "        for dut in range(self.Parent.NDUTPlanes):\n",
    "            c = self.Parent.load_calibration(dut)\n",
    "            if not c.FitFileName.exists():\n",
    "                c.save_fit_pars()\n",
    "        return c.CalPath\n",
    "\n",
    "    @property\n",
    "    def soft(self):\n",
    "        return self.SoftDir.joinpath('bin', 'euCliConverter')\n",
    "\n",
    "    def options(self, max_events=None):\n",
    "        return f'-c {self.generate_fit_files()}{f\" -m {max_events}\" if max_events is not None else \"\"}'\n",
    "\n",
    "    def convert(self, max_events=None):\n",
    "        \"\"\" convert binary raw file to root file with eudaq\"\"\"\n",
    "        Converter.download_raw_file(self.RawFilePath)\n",
    "        self.OutFilePath.parent.mkdir(exist_ok=True)\n",
    "        cmd = f'{self.soft} -i {self.RawFilePath} -o {self.OutFilePath} {self.options(max_events)}'\n",
    "        info(f'Convert {self.RawFilePath.name} to {self.OutFilePath.name} using {self.soft.name}\\n')\n",
    "        info(f'{cmd}\\n')\n",
    "        check_call(cmd, shell=True)\n",
    "        for f in Path().glob('AutoDict_vector*'):\n",
    "            remove_file(f)\n",
    "    # endregion CONVERT\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region ANALYSIS\n",
    "    def get(self, p, g, k):\n",
    "        return array(self.F[f'Plane{p}'][g][k])\n",
    "\n",
    "    def z(self):\n",
    "        return self.Parent.Proteus.z_positions(raw=True)[:self.NT]\n",
    "\n",
    "    def l2g(self, x, y, p, step=None):\n",
    "        p = self.Planes[p]\n",
    "        a = self.Parent.Proteus.alignment(choose(step, self.AtStep))['sensors'][p.Number]\n",
    "        ox, oy = array(a['offset'][:2])\n",
    "        rx, ry = array(a['unit_u']), a['unit_v']\n",
    "        return transform(x, y, sx=p.PX, sy=p.PY, ox=ox, oy=oy, rx=rx, ry=ry, order='trs')\n",
    "\n",
    "    def xy(self, p, cut=...):\n",
    "        return [self.get(p, 'Clusters', k)[cut] for k in ['X', 'Y']]\n",
    "\n",
    "    def txy(self, p, cut=...):\n",
    "        return [self.get(p, 'Tracks', k)[cut] for k in ['X', 'Y']]\n",
    "\n",
    "    def uv(self, p, cut=..., step=None):\n",
    "        return self.l2g(*self.xy(p, cut), p, step)\n",
    "\n",
    "    def uvs(self, step=None):\n",
    "        return array([self.uv(p, c, step) for p, c in zip(self.P, self.cuts())])\n",
    "\n",
    "    def tuv(self, p, cut=..., step=None):\n",
    "        return self.l2g(*self.txy(p, cut), p, step)\n",
    "\n",
    "    def tuvs(self, step=None):\n",
    "        return array([self.tuv(p, self.cut(), step) for p in self.P])\n",
    "\n",
    "    def du(self, p, step=None):\n",
    "        c = self.all_planes()\n",
    "        return self.uv(p, self.cuts(c)[p], step)[0] - self.tuv(p, self.cut(c), step)[0]\n",
    "\n",
    "    def all_planes(self):\n",
    "        return array(self.F['Tracks']['Size']) == self.NT\n",
    "\n",
    "    def cuts(self, cut=True):\n",
    "        n = [self.get(p, 'Clusters', 'Size') > 0 for p in self.P]\n",
    "        c = all(n, axis=0) & cut\n",
    "        return [c[i] for i in n]\n",
    "\n",
    "    def res(self):\n",
    "        return array([Gauss(self.draw_du(p, show=False)).fit(draw=False).get_pars(err=False)[1:] for p in self.P])\n",
    "\n",
    "    def cut(self, cut=True):\n",
    "        return all([self.get(p, 'Clusters', 'Size') > 0 for p in self.P], axis=0) & cut\n",
    "\n",
    "    def draw_clu_u(self, i=0, step=None):\n",
    "        self.Draw.graph(self.z(), self.uvs(step)[:, 0, :].T[i], x_tit='Z [mm]', y_tit='Cluster U [mm]')\n",
    "\n",
    "    def draw_track_u(self, i=0, step=None):\n",
    "        self.Draw.graph(self.z(), self.tuvs(step)[:, 0, :].T[i], x_tit='Z [mm]', y_tit='Track U [mm]')\n",
    "\n",
    "    def draw_du(self, p=0, step=None, **dkw):\n",
    "        return self.Draw.distribution(self.du(p, step) * 1e3, **prep_kw(dkw, x_tit='dU [#mum]'))\n",
    "\n",
    "    def draw_clu_y(self, i=0, step=None):\n",
    "        self.Draw.graph(self.z(),  self.uvs(step)[:, 1, :].T[i], x_tit='Z [mm]', y_tit='V [mm]')\n",
    "    # ----------------------------------------\n",
    "    # endregion ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
