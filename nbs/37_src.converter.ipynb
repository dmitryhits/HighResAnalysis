{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src.converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter\n",
    "> adds clustering and charge to trees created with pXar (created on August 30th 2018 by M. Reichmann (remichae@phys.ethz.ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/10\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import uproot\n",
    "from numpy import all, ones, count_nonzero  # noqa\n",
    "from uproot import ReadOnlyDirectory\n",
    "from uproot.models import TTree\n",
    "from pathlib import Path\n",
    "import awkward as aw  \n",
    "\n",
    "from HighResAnalysis.src.proteus import Proteus\n",
    "from HighResAnalysis.src.run import Run, Analysis, init_batch, DUT, Batch\n",
    "from HighResAnalysis.src.analysis import BeamTest\n",
    "from HighResAnalysis.utility.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Converter:\n",
    "    \"\"\"\n",
    "    Converts EUDAQ2 raw files in several steps into hdf5 files.\n",
    "    STEP  0: raw -> root                  (EUDAQ2)\n",
    "    STEP  1: noisescan                    (proteus)\n",
    "    STEP  2: alignment                    (proteus)\n",
    "    STEP  3: track reconstruction         (proteus)\n",
    "    STEP  4: root -> hdf5                 (python)\n",
    "    \"\"\"\n",
    "\n",
    "    DUTName = None\n",
    "\n",
    "    def __init__(self, data_dir: Path, run_number, dut_name=None):\n",
    "\n",
    "        self.T0 = time()\n",
    "        self.T1 = timedelta(seconds=0)\n",
    "        self.Run = Run(run_number, 0, data_dir)\n",
    "        self.DUTName = dut_name  # only used in CERNConverter\n",
    "        self.DUTs = self.init_duts()\n",
    "\n",
    "        # DIRECTORIES\n",
    "        self.DataDir = data_dir\n",
    "        self.SaveDir = data_dir.joinpath('data')\n",
    "        self.SoftDir = Path(Analysis.Config.get('SOFTWARE', 'dir')).expanduser()\n",
    "\n",
    "        self.NTelPlanes = Analysis.Config.getint('TELESCOPE', 'planes')\n",
    "        self.NDUTPlanes = self.Run.NDUTs\n",
    "\n",
    "        # PRE-CONVERTER\n",
    "        self.Raw = self.init_raw()\n",
    "        self.Proteus = self.init_proteus()\n",
    "\n",
    "        # FILES\n",
    "        self.OutFilePath = self.SaveDir.joinpath(f'run{self.Run:04d}.hdf5')\n",
    "        self.RawFile: ReadOnlyDirectory = None  # noqa\n",
    "        self.F = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__} of {self.Run!r}'\n",
    "\n",
    "    def run(self, force=False, steps=None, rm=True):\n",
    "        if force or not self.OutFilePath.exists():\n",
    "            self.T0 = info(f'Starting {self!r}\\n')\n",
    "            for i, (s, f) in enumerate(choose(steps, self.steps)):\n",
    "                if not f.exists() or force:\n",
    "                    print_banner(f'Start converter step {i}: {s.__doc__}')\n",
    "                    try:\n",
    "                        s(force=force) if 'force' in signature(s).parameters else s()\n",
    "                    except Exception as err:\n",
    "                        warning(f'converter crashed: {err}')\n",
    "                        remove_file(f)\n",
    "                        return False\n",
    "                else:\n",
    "                    info(f'found outfile of step {i}, continue with next step ({f})')\n",
    "            if rm:\n",
    "                self.remove_aux_files()\n",
    "            add_to_info(self.T0, f'\\nFinished {self!r} in ', color=GREEN)\n",
    "            self.T1 = timedelta(seconds=time() - self.T0)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def finished(self):\n",
    "        return self.T1.total_seconds() > 0\n",
    "\n",
    "    def raw2root(self, force=True):\n",
    "        self.run(force=force, steps=self.first_steps, rm=False)\n",
    "\n",
    "    def realign(self, rm=True):\n",
    "        self.raw2root()\n",
    "        self.Proteus.align(force=True)\n",
    "        if rm:\n",
    "            self.remove_aux_files()\n",
    "\n",
    "    @property\n",
    "    def first_steps(self):\n",
    "        return self.Raw.Steps\n",
    "\n",
    "    @property\n",
    "    def steps(self):\n",
    "        return self.first_steps + self.Proteus.Steps + [(self.root2hdf5, self.OutFilePath)]\n",
    "\n",
    "    @property\n",
    "    def aux_files(self):\n",
    "        return [self.Proteus.RawFilePath, self.Proteus.OutFilePath, self.Proteus.HistFilePath]\n",
    "\n",
    "    @property\n",
    "    def raw_files(self):\n",
    "        return [self.Raw.RawFilePath]\n",
    "\n",
    "    def remove_files(self, all_=False):\n",
    "        for s, f in self.steps:\n",
    "            if f.suffix == '.root' or f.suffix == '.hdf5' or all_:\n",
    "                remove_file(f)\n",
    "\n",
    "    def remove_raw_files(self, warn=True):\n",
    "        remove_file(*self.raw_files, warn=warn)\n",
    "\n",
    "    def remove_aux_files(self):\n",
    "        remove_file(*self.aux_files)\n",
    "\n",
    "    def clean(self):\n",
    "        self.remove_aux_files()\n",
    "\n",
    "    @staticmethod\n",
    "    def download_raw_file(f: Path, out=True, force=False):\n",
    "        if not f.exists() or force:\n",
    "            server, loc = [Analysis.Config.get('data', n) for n in ['server', 'server dir']]\n",
    "            info(f'downloading DUT raw file from {server}:{loc}', prnt=out)\n",
    "            f.parent.mkdir(exist_ok=True)\n",
    "            return download_file(server, Path(loc).expanduser().joinpath(*f.parts[-4:]), f, out)\n",
    "\n",
    "    def copy_raw_files(self, out=True, force=False):\n",
    "        return [self.download_raw_file(f, out, force) for f in self.raw_files]\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region INIT\n",
    "    @classmethod\n",
    "    def from_run(cls, run: Run, dut_name=None):\n",
    "        conv = cls(run.TCDir, run.Number, dut_name)\n",
    "        conv.Run = run\n",
    "        return conv\n",
    "\n",
    "    @classmethod\n",
    "    def from_ana(cls, run_number, dut=0, ana: Analysis = None):\n",
    "        ana = choose(ana, Analysis)\n",
    "        return cls.from_run(Run.from_ana(run_number, dut, ana))\n",
    "\n",
    "    def init_proteus(self):\n",
    "        soft_dir = self.SoftDir.joinpath(Analysis.Config.get('SOFTWARE', 'proteus'))\n",
    "        data_dir = self.DataDir.joinpath('proteus')\n",
    "        conf_dir = Dir.joinpath('proteus', self.DataDir.stem)\n",
    "        me, se = [Analysis.Config.getint('align', opt) for opt in ['max events', 'skip events']]\n",
    "        return Proteus(soft_dir, data_dir, conf_dir, raw_file=self.proteus_raw_file_path(), max_events=me, skip_events=se, dut_pos=self.dut_pos, duts=self.dut_names, align_run=self.Run.Number)\n",
    "\n",
    "    def init_raw(self):\n",
    "        from src.raw import Raw\n",
    "        return Raw(self)\n",
    "\n",
    "    def init_event_alignment(self):\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def calibration(self):\n",
    "        from src.calibration import Calibration\n",
    "        return Calibration\n",
    "\n",
    "    def init_duts(self):\n",
    "        return [DUT(i, self.Run.Info) for i in range(self.Run.NDUTs)]\n",
    "\n",
    "    @property\n",
    "    def dut_names(self):\n",
    "        return [dut.Name for dut in self.DUTs]\n",
    "\n",
    "    @property\n",
    "    def dut_pos(self):\n",
    "        return [dut.Position for dut in self.DUTs]\n",
    "\n",
    "    def load_calibration(self, dut_nr=None):\n",
    "        return self.calibration(self.Run if dut_nr is None else Run(self.Run.Number, dut_nr, self.Run.TCDir))\n",
    "\n",
    "    def proteus_raw_file_path(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def load_file(self, opt='w'):\n",
    "        return h5py.File(self.OutFilePath, opt)\n",
    "    # endregion INIT\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region HDF5\n",
    "    def root2hdf5(self):\n",
    "        \"\"\" convert tracked root file to hdf5 file. \"\"\"\n",
    "        remove_file(self.OutFilePath)  # remove hdf5 file if it exists\n",
    "        start_time = info('starting root -> hdf5 conversion ...')\n",
    "\n",
    "        self.F = self.load_file()\n",
    "        self.RawFile = uproot.open(self.Proteus.OutFilePath)\n",
    "\n",
    "        self.add_tracks()\n",
    "        self.add_planes()\n",
    "\n",
    "        add_to_info(start_time, '\\nFinished hdf5 conversion in')\n",
    "        self.F.close()\n",
    "        self.F = None\n",
    "\n",
    "    def add_tracks(self):\n",
    "        t0 = info('adding track information ...', endl=False)\n",
    "        g = self.F.create_group('Tracks')\n",
    "        b = array([['evt_frame', 'Events', 'u4'], ['evt_ntracks', 'N', 'u1'],\n",
    "                   ['trk_size',  'Size',   'f2'],\n",
    "                   ['trk_chi2',  'Chi2',   'f2'], ['trk_dof', 'Dof', 'u1'],\n",
    "                   ['trk_du',    'SlopeX', 'f2'], ['trk_dv', 'SlopeY', 'f2']]).T\n",
    "        tree = self.RawFile['C0/tracks_clusters_matched']  # same for all planes\n",
    "        self.add_time_stamp()\n",
    "        self.add_data(tree, g, b)\n",
    "        add_to_info(t0, color=GREEN)\n",
    "\n",
    "    @property\n",
    "    def time_stamp_file(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def get_time_stamp(self):\n",
    "        t = array(uproot.open(self.time_stamp_file)['Event']['TimeStamp'])\n",
    "        return ((t - t[0]) / 1e9).astype('f4')  # time stamp is just a number counting up\n",
    "\n",
    "    def add_time_stamp(self):\n",
    "        self.F.create_group('Event').create_dataset('Time', data=self.get_time_stamp())\n",
    "\n",
    "    def add_planes(self):\n",
    "        n = len(self.RawFile.keys(recursive=False))  # noqa (raises stupid warning)\n",
    "        info(f'adding {n} planes ... ')\n",
    "        PBAR.start(n * 2)\n",
    "        for pl in range(n):\n",
    "            try:\n",
    "                self.add_plane(pl)\n",
    "            except Exception as err:\n",
    "                PBAR.finish()\n",
    "                raise ValueError(f'root2hdf crashed adding plane {pl} having {err}')\n",
    "\n",
    "    def add_plane(self, i):\n",
    "        g = self.F.create_group(f'Plane{i}')\n",
    "        key = list(self.RawFile.keys(recursive=False))[i]\n",
    "\n",
    "        # mask\n",
    "        m_tree = self.RawFile[f'{key}/masked_pixels']\n",
    "        g.create_dataset('Mask', data=array(list(m_tree.arrays(library='np').values()), 'u2'))\n",
    "\n",
    "        # cluster & track interpolations\n",
    "        tree = self.RawFile[f'{key}/tracks_clusters_matched']\n",
    "        self.add_plane_tracks(g, tree)\n",
    "        self.add_clusters(g, tree)\n",
    "        if i >= self.NTelPlanes + self.Proteus.NRefPlanes:\n",
    "            self.add_trigger_info(g)\n",
    "\n",
    "    @update_pbar\n",
    "    def add_plane_tracks(self, group, tree: TTree):\n",
    "        g = group.create_group('Tracks')\n",
    "        b = array([['trk_u', 'U', 'f2'], ['trk_v', 'V', 'f2'], ['trk_col', 'X', 'f4'], ['trk_row', 'Y', 'f4'], ['trk_std_u', 'eU', 'f2'], ['trk_std_v', 'eV', 'f2']]).T\n",
    "        self.add_data(tree, g, b)\n",
    "\n",
    "    @update_pbar\n",
    "    def add_clusters(self, group, tree: TTree):\n",
    "        g = group.create_group('Clusters')\n",
    "        cs = self.add_data(tree, g, array([['clu_size', 'Size', 'u2'], ['evt_nclusters', 'N', 'u2']]).T)['clu_size']\n",
    "        b = array([['clu_u', 'U', 'f2'], ['clu_v', 'V', 'f2'], ['clu_col', 'X', 'f2'], ['clu_row', 'Y', 'f2'], ['clu_value', 'Charge', 'i']]).T\n",
    "        self.add_data(tree, g, b, cut=cs > 0)  # filter out the nan events\n",
    "\n",
    "    def trigger_info_file(self):\n",
    "        return self.Raw.OutFilePath\n",
    "\n",
    "    def add_trigger_info(self, group):\n",
    "        tree = uproot.open(self.trigger_info_file())[f'{group.name}/Hits']\n",
    "        g = group.create_group('Trigger')\n",
    "        b = array([[key, key.replace('Trigger', ''), 'u1'] for key in tree.keys(filter_name='Trigger*')]).T\n",
    "        self.add_data(tree, g, b)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_data(tree: TTree, g, b, cut=...):\n",
    "        data = tree.arrays(b[0], library='np')\n",
    "        for i, (old_name, new_name, dtype) in enumerate(b.T):\n",
    "            g.create_dataset(new_name, data=data[old_name][cut].astype(dtype))\n",
    "        return data\n",
    "    # endregion HDF5\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region ALIGN\n",
    "    def align_tree(self):\n",
    "        import uproot\n",
    "        hf = h5py.File(self.OutFilePath)\n",
    "        with uproot.recreate('bla.root') as f:\n",
    "            n = [array(hf[f'Plane{pl}']['Clusters']['Size']) > 0 for pl in range(self.NTelPlanes)]\n",
    "            cut = all(n, axis=0) & (array(hf['Tracks']['Size']) == self.NTelPlanes)\n",
    "            for pl in range(self.NTelPlanes):\n",
    "                d = f.mkdir(f'Plane{pl}')\n",
    "                ci = cut[n[pl]]\n",
    "                i = count_nonzero(ci)\n",
    "                d['Clusters'] = {'NClusters': ones(i, 'i'),\n",
    "                                 'Col': array(hf[f'Plane{pl}']['Clusters']['X'])[ci].astype('d').reshape((-1, 1)),\n",
    "                                 'Row': array(hf[f'Plane{pl}']['Clusters']['Y'])[ci].astype('d').reshape((-1, 1)),\n",
    "                                 'VarCol': ones((i, 1)),\n",
    "                                 'VarRow': ones((i, 1)),\n",
    "                                 'Value': ones((i, 1)),\n",
    "                                 'CovColRow': zeros((i, 1)),\n",
    "                                 'Timing': zeros((i, 1)),\n",
    "                                 'Track': ones((i, 1), 'i')}\n",
    "            f['Plane0']['Clusters'].show()\n",
    "    # endregion ALIGN\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # region MISC\n",
    "    @staticmethod\n",
    "    def check_root_version():\n",
    "        v = gROOT.GetVersion()\n",
    "        return True if v.startswith('6') else critical(f'ROOT 6 required for the conversion! Current version: {v}')\n",
    "    # endregion MISC\n",
    "    # ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def batch_converter(cls: Converter):\n",
    "    class BatchConverter(cls):\n",
    "\n",
    "        def __init__(self, beam_test: BeamTest, batch_name):\n",
    "\n",
    "            self.Batch = batch_name if isinstance(batch_name, Batch) else init_batch(batch_name, 0, beam_test)\n",
    "            super().__init__(beam_test.Path, self.Batch.Runs[0].Number, self.Batch.DUTName)\n",
    "            self.OutFilePath = self.Batch.FileName\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f'{self.__class__.__name__} of {self.Batch!r}'\n",
    "\n",
    "        def proteus_raw_file_path(self):\n",
    "            return self.Batch.FileName.with_suffix('.root')\n",
    "\n",
    "        @classmethod\n",
    "        def from_batch(cls, b: Batch):\n",
    "            return cls(b.BeamTest, b)\n",
    "\n",
    "        def trigger_info_file(self):\n",
    "            return super().trigger_info_file().with_name(f'dut-{self.Batch.FileName.stem}.root')\n",
    "\n",
    "        @property\n",
    "        def time_stamp_file(self):\n",
    "            return self.trigger_info_file()\n",
    "\n",
    "    return BatchConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
